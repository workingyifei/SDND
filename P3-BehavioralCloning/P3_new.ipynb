{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import pickle\n",
    "from keras.models import model_from_json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the images into pandas dataframe\n",
    "df = pd.read_csv(\"driving_log.csv\", header=None, skipinitialspace=True, names=[\"center\", \"left\", \"right\",  \"angle\", \"throttle\", \"brake\", \"speed\"])\n",
    "\n",
    "# center+left+right\n",
    "center = pd.DataFrame({\"image_path\": df[\"center\"],\n",
    "                       \"angle\": df[\"angle\"]\n",
    "             })\n",
    "left = pd.DataFrame({\"image_path\": df[\"left\"],\n",
    "                       \"angle\": df[\"angle\"]+0.3\n",
    "             })\n",
    "right = pd.DataFrame({\"image_path\": df[\"right\"],\n",
    "                       \"angle\": df[\"angle\"]-0.3\n",
    "             })\n",
    "\n",
    "frame = [center, left, right]\n",
    "df = pd.concat(frame, ignore_index=True)\n",
    "\n",
    "\n",
    "X = df[\"image_path\"]\n",
    "Y = df[\"angle\"]\n",
    "Y = Y.astype(np.float32)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yifei/Documents/P3_new/IMG/right_2016_12_11_20_35_33_474.jpg'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.reindex()\n",
    "X_train.iloc[0]\n",
    "X_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 66, 200\n",
    "\n",
    "\n",
    "def image_preprocess(path):\n",
    "    image = mpimg.imread(path, format='jpg')\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    shape = image.shape\n",
    "    image = image[int(shape[0]/3):shape[0], 0:shape[1]]\n",
    "    image = cv2.resize(image, (img_cols, img_rows), interpolation=cv2.INTER_AREA)\n",
    "    image = np.array(image).astype(\"float32\")\n",
    "    return image\n",
    "\n",
    "def batchgen(X, Y):\n",
    "    while 1:\n",
    "        for i in range(len(X)):\n",
    "            image = image_preprocess(X.iloc[i])\n",
    "            image = image.reshape([1, img_rows, img_cols, 1])\n",
    "            y = np.array([[Y.iloc[i]]])\n",
    "            yield image, y\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True,\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4409,)\n",
      "(4409,)\n",
      "(490,)\n",
      "(490,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_5 (Lambda)                (None, 66, 200, 1)    0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 17, 50, 16)    1040        lambda_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "elu_17 (ELU)                     (None, 17, 50, 16)    0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 9, 25, 32)     12832       elu_17[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "elu_18 (ELU)                     (None, 9, 25, 32)     0           convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 5, 13, 64)     51264       elu_18[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 4160)          0           convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 4160)          0           flatten_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "elu_19 (ELU)                     (None, 4160)          0           dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 512)           2130432     elu_19[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 512)           0           dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "elu_20 (ELU)                     (None, 512)           0           dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 1)             513         elu_20[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 2196081\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "881/881 [==============================] - 64s - loss: 0.0856 - val_loss: 0.0543\n",
      "Epoch 2/200\n",
      "881/881 [==============================] - 58s - loss: 0.0379 - val_loss: 0.0509\n",
      "Epoch 3/200\n",
      "881/881 [==============================] - 55s - loss: 0.0434 - val_loss: 0.0613\n",
      "Epoch 4/200\n",
      "881/881 [==============================] - 55s - loss: 0.0490 - val_loss: 0.0420\n",
      "Epoch 5/200\n",
      "881/881 [==============================] - 76s - loss: 222.2283 - val_loss: 0.2010\n",
      "Epoch 6/200\n",
      "881/881 [==============================] - 73s - loss: 0.5457 - val_loss: 0.1640\n",
      "Epoch 7/200\n",
      "881/881 [==============================] - 65s - loss: 0.2641 - val_loss: 0.0799\n",
      "Epoch 8/200\n",
      "881/881 [==============================] - 56s - loss: 0.2239 - val_loss: 0.1049\n",
      "Epoch 9/200\n",
      "881/881 [==============================] - 51s - loss: 0.2235 - val_loss: 0.1450\n",
      "Epoch 10/200\n",
      "881/881 [==============================] - 51s - loss: 0.1802 - val_loss: 0.1430\n",
      "Epoch 11/200\n",
      "881/881 [==============================] - 53s - loss: 0.2014 - val_loss: 0.1396\n",
      "Epoch 12/200\n",
      "881/881 [==============================] - 58s - loss: 0.2025 - val_loss: 0.0765\n",
      "Epoch 13/200\n",
      "881/881 [==============================] - 51s - loss: 0.1964 - val_loss: 0.0833\n",
      "Epoch 14/200\n",
      "881/881 [==============================] - 52s - loss: 0.1718 - val_loss: 0.1283\n",
      "Epoch 15/200\n",
      "881/881 [==============================] - 51s - loss: 0.1744 - val_loss: 0.0829\n",
      "Epoch 16/200\n",
      "881/881 [==============================] - 53s - loss: 0.1774 - val_loss: 0.0915\n",
      "Epoch 17/200\n",
      "881/881 [==============================] - 52s - loss: 0.1656 - val_loss: 0.1696\n",
      "Epoch 18/200\n",
      "881/881 [==============================] - 71s - loss: 0.1647 - val_loss: 0.0869\n",
      "Epoch 19/200\n",
      "881/881 [==============================] - 61s - loss: 0.1361 - val_loss: 0.1776\n",
      "Epoch 20/200\n",
      "881/881 [==============================] - 60s - loss: 0.1266 - val_loss: 0.1624\n",
      "Epoch 21/200\n",
      " 82/881 [=>............................] - ETA: 62s - loss: 0.1526"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f09daeef47a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                     verbose=1)\n\u001b[0m",
      "\u001b[0;32m/Users/yifei/anaconda3/envs/keras/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    880\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m/Users/yifei/anaconda3/envs/keras/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1459\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1460\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1462\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yifei/anaconda3/envs/keras/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yifei/anaconda3/envs/keras/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yifei/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yifei/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yifei/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/yifei/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yifei/anaconda3/envs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Build the network\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Activation, Dropout, MaxPooling2D, Convolution2D, Lambda, ELU, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "            \n",
    " \n",
    "input_shape = (66, 200, 1)\n",
    "pool_size = (2, 3)\n",
    "img_rows, img_cols = 66, 200\n",
    "\n",
    "batch_size = 5\n",
    "samples_per_epoch = int(len(X_train)/batch_size)\n",
    "nb_epoch = 200\n",
    "val_size = int(samples_per_epoch/10.0)\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(MaxPooling2D(pool_size=pool_size,input_shape=input_shape))\n",
    "model.add(Lambda(lambda x: x/127.5 - 1., input_shape=input_shape))\n",
    "model.add(Convolution2D(16, 8, 8, subsample=(4, 4), border_mode=\"same\"))\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(32, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(64, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(.2))\n",
    "model.add(ELU())\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(.5))\n",
    "model.add(ELU())\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.summary()\n",
    "\n",
    "\n",
    "history = model.fit_generator(batchgen(X_train, Y_train),\n",
    "                    samples_per_epoch=samples_per_epoch, \n",
    "                    nb_epoch=nb_epoch,\n",
    "                    validation_data=batchgen(X_val, Y_val),\n",
    "                    nb_val_samples=val_size,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load model to .json\n",
    "import json\n",
    "json_string = model_json = model.to_json()\n",
    "with open('model.json', 'w') as f:\n",
    "    json.dump(model_json, f)\n",
    "\n",
    "\n",
    "\n",
    "# save weights as .h5\n",
    "json_string = model.to_json()\n",
    "model = model_from_json(json_string)\n",
    "model.save_weights(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
